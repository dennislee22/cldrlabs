<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Add Nvidia GPU</title>
    <link
      rel="stylesheet"
      href="/assets/css/style.css"
    />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link
      rel="stylesheet"
      href="/assets/css/rouge.css"
    />
    <script src="/assets/js/accordian.js"></script>
    <script src="/assets/js/heading_links.js"></script>
    
    <script src="/assets/js/vendor/lunr.min.js"></script>
    <script src="/assets/js/search.js"></script>
    
  </head>

  <body>
    <div class="chrome">
      <div class="chrome:nav">
      <img src="/assets/images/cloudera_logo_WHITE.png" alt="Link to GitHub Repository">
  
</div>

      <div class="chrome:body">
        <header class="chrome:header">
  <div class="chrome:header_title">
    <a href="/" class="text-grey-800 no-underline hover:no-underline focus:no-underline">
      <span class="text-3xl">Cloudera Labs</span>
    </a>
  </div>
   <div class="chrome:header_item">
  <svg xmlns="http://www.w3.org/2000/svg" width="26" height="26" focusable="false" viewBox="0 0 26 26">
  <g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2">
    <circle cx="11" cy="11" r="7"/>
    <path d="M16 16l6 6"/>
  </g>
</svg>

  <form id="search">
    <input
      type="text"
      id="search_input"
      name="search_query"
      class="search_input"
      placeholder="Search Cloudera Labs"
      autocomplete="off"
    />
  </form>
</div>
 
</header>

        <div class="chrome:content">
          <div class="chrome:main">
            
            
            <h1 id="add-nvidia-gpu">Add Nvidia GPU</h1>
            
            
            
<p>This article describes the steps to install the Nvidia GPU software driver and its associated software in the CDP PvC Data Services platform with Openshift solution. These implementation steps are to be carried out after the Openshift platform installation. This article also describes the steps to test the Nvidia GPU card in the CML workspace.</p>

<ul id="markdown-toc">
  <li><a href="#assumption" id="markdown-toc-assumption">Assumption</a></li>
  <li><a href="#install-nfd-operator" id="markdown-toc-install-nfd-operator">Install NFD Operator</a></li>
  <li><a href="#install-nvidia-gpu-operator" id="markdown-toc-install-nvidia-gpu-operator">Install Nvidia GPU Operator</a></li>
  <li><a href="#nvidia-gpu-card-testing-and-verification-in-cml" id="markdown-toc-nvidia-gpu-card-testing-and-verification-in-cml">Nvidia GPU Card Testing and Verification in CML</a></li>
  <li><a href="#taint-the-openshift-worker-node-with-nvidia-gpu-card" id="markdown-toc-taint-the-openshift-worker-node-with-nvidia-gpu-card">Taint the Openshift Worker Node with Nvidia GPU Card</a></li>
</ul>

<hr />
<h2 id="assumption">Assumption</h2>

<ul>
  <li>The software version of each CDP Private Cloud Data Services component in this demo is described below.</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Software</th>
      <th style="text-align: left">Version</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">CDP PvC Base</td>
      <td style="text-align: left">7.1.7 SP1</td>
    </tr>
    <tr>
      <td style="text-align: left">Cloudera Manager</td>
      <td style="text-align: left">7.6.5</td>
    </tr>
    <tr>
      <td style="text-align: left">CDP PvC Data Services</td>
      <td style="text-align: left">1.4.0</td>
    </tr>
    <tr>
      <td style="text-align: left">Red Hat Openshift Container Platform (OCP)</td>
      <td style="text-align: left">4.8</td>
    </tr>
    <tr>
      <td style="text-align: left">Red Hat Openshift Container Storage (OCS)</td>
      <td style="text-align: left">4.8</td>
    </tr>
  </tbody>
</table>

<h2 id="install-nfd-operator">Install NFD Operator</h2>

<ol>
  <li>
    <p>In Openshift dashboard, navigate to <code class="language-plaintext highlighter-rouge">Operators</code> &gt; <code class="language-plaintext highlighter-rouge">OperatorHub</code>. Search for <code class="language-plaintext highlighter-rouge">Node Feature Discovery</code>. Install the NFD operator and its API.</p>

    <p><img src="../../assets/images/gpu/nfd1.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nfd2.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nfd3.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nfd4.png" alt="" /></p>
  </li>
  <li>
    <p>SSH into the Openshift bastion node and run the following command to ensure that <code class="language-plaintext highlighter-rouge">ocpgpu.cdpkvm.cldr</code> host (with GPU card installed) has <code class="language-plaintext highlighter-rouge">pci-10de.present=true</code> field in the node specification. This indicates the presence of Nvidia GPU card in this particular worker node.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc describe node ocpgpu.ocp4.cdpkvm.cldr | <span class="nb">grep </span>pci-10de.present
                     feature.node.kubernetes.io/pci-10de.present<span class="o">=</span><span class="nb">true</span>
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="install-nvidia-gpu-operator">Install Nvidia GPU Operator</h2>

<ol>
  <li>
    <p>Navigate to <code class="language-plaintext highlighter-rouge">Operators</code> &gt; <code class="language-plaintext highlighter-rouge">OperatorHub</code>. Search for <code class="language-plaintext highlighter-rouge">Nvidia GPU Operator</code>. Install the operator and its <code class="language-plaintext highlighter-rouge">ClusterPolicies</code>.</p>

    <p><img src="../../assets/images/gpu/nvidiaocp1.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nvidiaocp2.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nvidiaocp3.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nvidiaocp4.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/nvidiaocp5.png" alt="" /></p>
  </li>
  <li>
    <p>SSH into the Openshift bastion node and run the following command to verify the successful installation of the operator and the clusterPolicy.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc get pods,daemonset <span class="nt">-n</span> nvidia-gpu-operator
 NAME                                                     READY   STATUS      RESTARTS   AGE
 pod/gpu-feature-discovery-l7pqc                          1/1     Running     0          6m46s
 pod/gpu-operator-765ff6c665-mznvk                        1/1     Running     0          7m50s
 pod/nvidia-container-toolkit-daemonset-6brmr             1/1     Running     0          6m47s
 pod/nvidia-cuda-validator-8brpz                          0/1     Completed   0          2m50s
 pod/nvidia-dcgm-5txs7                                    1/1     Running     0          6m47s
 pod/nvidia-dcgm-exporter-wj4dg                           1/1     Running     0          6m46s
 pod/nvidia-device-plugin-daemonset-b2k5x                 1/1     Running     0          6m47s
 pod/nvidia-device-plugin-validator-29b9g                 0/1     Completed   0          2m32s
 pod/nvidia-driver-daemonset-48.84.202208152344-0-cxsld   2/2     Running     0          6m47s
 pod/nvidia-mig-manager-kqzk5                             1/1     Running     0          87s
 pod/nvidia-node-status-exporter-2xsdc                    1/1     Running     0          6m47s
 pod/nvidia-operator-validator-f2zdm                      1/1     Running     0          6m47s

 NAME                                                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                                                                                        AGE
 daemonset.apps/gpu-feature-discovery                          1         1         1       1            1           nvidia.com/gpu.deploy.gpu-feature-discovery<span class="o">=</span><span class="nb">true                                                                     </span>6m46s
 daemonset.apps/nvidia-container-toolkit-daemonset             1         1         1       1            1           nvidia.com/gpu.deploy.container-toolkit<span class="o">=</span><span class="nb">true                                                                         </span>6m47s
 daemonset.apps/nvidia-dcgm                                    1         1         1       1            1           nvidia.com/gpu.deploy.dcgm<span class="o">=</span><span class="nb">true                                                                                      </span>6m47s
 daemonset.apps/nvidia-dcgm-exporter                           1         1         1       1            1           nvidia.com/gpu.deploy.dcgm-exporter<span class="o">=</span><span class="nb">true                                                                             </span>6m46s
 daemonset.apps/nvidia-device-plugin-daemonset                 1         1         1       1            1           nvidia.com/gpu.deploy.device-plugin<span class="o">=</span><span class="nb">true                                                                             </span>6m47s
 daemonset.apps/nvidia-driver-daemonset-48.84.202208152344-0   1         1         1       1            1           feature.node.kubernetes.io/system-os_release.OSTREE_VERSION<span class="o">=</span>48.84.202208152344-0,nvidia.com/gpu.deploy.driver<span class="o">=</span><span class="nb">true   </span>6m47s
 daemonset.apps/nvidia-mig-manager                             1         1         1       1            1           nvidia.com/gpu.deploy.mig-manager<span class="o">=</span><span class="nb">true                                                                               </span>6m46s
 daemonset.apps/nvidia-node-status-exporter                    1         1         1       1            1           nvidia.com/gpu.deploy.node-status-exporter<span class="o">=</span><span class="nb">true                                                                      </span>6m47s
 daemonset.apps/nvidia-operator-validator                      1         1         1       1            1           nvidia.com/gpu.deploy.operator-validator<span class="o">=</span><span class="nb">true                                                                        </span>6m47s
</code></pre></div>    </div>
  </li>
  <li>
    <p>Verify that the Nvidia GPU card can be consumed by a newly provisioned CUDA pod.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc new-project nvidia-test

 <span class="o">[</span>root@ocpbastion ~]# <span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | oc create -f -
 &gt; 
 &gt; apiVersion: v1
 &gt; kind: Pod
 &gt; metadata:
 &gt;   name: cuda-vectoradd
 &gt; spec:
 &gt;  restartPolicy: OnFailure
 &gt;  containers:
 &gt;  - name: cuda-vectoradd
 &gt;    image: "nvidia/samples:vectoradd-cuda11.2.1"
 &gt;    resources:
 &gt;      limits:
 &gt;        nvidia.com/gpu: 1
 &gt; EOF
 pod/cuda-vectoradd created

 [root@ocpbastion ~]# oc get pods
 NAME             READY   STATUS      RESTARTS   AGE
 cuda-vectoradd   0/1     Completed   0          13s

 [root@ocpbastion ~]# oc logs cuda-vectoradd
 [Vector addition of 50000 elements]
 Copy input data from the host memory to the CUDA device
 CUDA kernel launch with 196 blocks of 256 threads
 Copy output data from the CUDA device to the host memory
 Test PASSED
 Done

 [root@ocpbastion ~]# oc describe pod cuda-vectoradd | grep -i Node:
 Node:         ocpgpu.ocp4.cdpkvm.cldr/10.15.4.185
</span></code></pre></div>    </div>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc <span class="nb">exec</span> <span class="nt">-it</span> nvidia-driver-daemonset-48.84.202208152344-0-cxsld <span class="nt">--</span> nvidia-smi
 Defaulted container <span class="s2">"nvidia-driver-ctr"</span> out of: nvidia-driver-ctr, openshift-driver-toolkit-ctr, k8s-driver-manager <span class="o">(</span>init<span class="o">)</span>
 Fri Aug 26 06:07:36 2022       
 +-----------------------------------------------------------------------------+
 | NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
 |-------------------------------+----------------------+----------------------+
 | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
 | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
 |                               |                      |               MIG M. |
 |<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
 |   0  NVIDIA A100-PCI...  On   | 00000000:07:00.0 Off |                    0 |
 | N/A   28C    P0    33W / 250W |      0MiB / 40536MiB |      0%      Default |
 |                               |                      |             Disabled |
 +-------------------------------+----------------------+----------------------+
                                                                               
 +-----------------------------------------------------------------------------+
 | Processes:                                                                  |
 |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
 |        ID   ID                                                   Usage      |
 |<span class="o">=============================================================================</span>|
 |  No running processes found                                                 |
 +-----------------------------------------------------------------------------+

 <span class="o">[</span>root@ocpbastion ~]# oc describe pod nvidia-driver-daemonset-48.84.202208152344-0-cxsld  | <span class="nb">grep </span>Node:
 Node:                 ocpgpu.ocp4.cdpkvm.cldr/10.15.4.185
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="nvidia-gpu-card-testing-and-verification-in-cml">Nvidia GPU Card Testing and Verification in CML</h2>

<ol>
  <li>
    <p>Assuming a CML workspace is already provisioned in the CDP PvC Data Services platform, navigate to <code class="language-plaintext highlighter-rouge">Site Administration</code> &gt; <code class="language-plaintext highlighter-rouge">Runtime/Engine</code>. Select the number for <code class="language-plaintext highlighter-rouge">Maximum GPUs per Session/GPU</code>. This procedure effectively allows the CML session to consume the GPU card.</p>

    <p><img src="../../assets/images/gpu/cmlgpu1.png" alt="" /></p>
  </li>
  <li>
    <p>Create a CML project and start a new session by selecting the <code class="language-plaintext highlighter-rouge">Workbench</code> editor with Python kernel alongside <code class="language-plaintext highlighter-rouge">Nvidia GPU</code> edition. Choose the number of GPU to use - in this demo, the quantity is 1.</p>

    <p><img src="../../assets/images/gpu/gpuocpsession1.png" alt="" /></p>
  </li>
  <li>
    <p>Create a new Python file and run the following script. Also, open the terminal session and run <code class="language-plaintext highlighter-rouge">nvidia-smi</code> tool. The output shows the Nvidia GPU card details.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kt">!pip3</span> <span class="s">install torch</span>
 <span class="s">import torch</span>
    
 <span class="s">torch.cuda.is_available()</span>
 <span class="s">torch.cuda.device_count()</span>
 <span class="s">torch.cuda.get_device_name(0)</span>
</code></pre></div>    </div>

    <p><img src="../../assets/images/gpu/gpuocpsession2.png" alt="" /></p>
  </li>
  <li>
    <p>Navigate to the CML project main page and a check at the user resources dashboard displays the GPU card availability.</p>

    <p><img src="../../assets/images/gpu/gpuecssession3.png" alt="" /></p>

    <p><img src="../../assets/images/gpu/gpuecssession4.png" alt="" /></p>
  </li>
  <li>
    <p>SSH into the Openshift bastion node and run the following command to verify the node that hosting the above CML project session pod is <code class="language-plaintext highlighter-rouge">ocpgpu.cdpkvm.cldr</code>.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc <span class="nt">-n</span> workspace-user-1 describe pod buldb59dst035j13 | <span class="nb">grep </span>Node:
 Node:         ocpgpu.ocp4.cdpkvm.cldr/10.15.4.185
</code></pre></div>    </div>
  </li>
  <li>
    <p>When a process is consuming the Nvidia GPU, the output of <code class="language-plaintext highlighter-rouge">nvidia-smi</code> tool will show the PID of that process (in this case, the CML session pod).</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc <span class="nt">-n</span> nvidia-gpu-operator <span class="nb">exec</span> <span class="nt">-it</span> nvidia-driver-daemonset-48.84.202208152344-0-r8rpv <span class="nt">--</span> nvidia-smi
 Defaulted container <span class="s2">"nvidia-driver-ctr"</span> out of: nvidia-driver-ctr, openshift-driver-toolkit-ctr, k8s-driver-manager <span class="o">(</span>init<span class="o">)</span>
 Fri Aug 26 07:42:07 2022       
 +-----------------------------------------------------------------------------+
 | NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
 |-------------------------------+----------------------+----------------------+
 | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
 | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
 |                               |                      |               MIG M. |
 |<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
 |   0  NVIDIA A100-PCI...  On   | 00000000:07:00.0 Off |                    0 |
 | N/A   30C    P0    44W / 250W |  39326MiB / 40536MiB |     12%      Default |
 |                               |                      |             Disabled |
 +-------------------------------+----------------------+----------------------+
                                                                               
 +-----------------------------------------------------------------------------+
 | Processes:                                                                  |
 |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
 |        ID   ID                                                   Usage      |
 |<span class="o">=============================================================================</span>|
 |    0   N/A  N/A    189226      C   /usr/local/bin/python3.9        39323MiB |
 +-----------------------------------------------------------------------------+
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="taint-the-openshift-worker-node-with-nvidia-gpu-card">Taint the Openshift Worker Node with Nvidia GPU Card</h2>
<ol>
  <li>
    <p>Reserve the worker node (with Nvidia GPU Card installed) for any CML session that requires GPU card by running the following command. This will disallow all other non-GPU related workloads to be scheduled in this particular node.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">[</span>root@ocpbastion ~]# oc adm taint node ocpgpu.ocp4.cdpkvm.cldr nvidia.com/gpu<span class="o">=</span><span class="nb">true</span>:NoSchedule
 node/ocpgpu.ocp4.cdpkvm.cldr tainted
</code></pre></div>    </div>
  </li>
</ol>

            
          </div>
           <div class="chrome:sidebar">
  
    
      
      
      
      <button
        id="sidebar_item:ansible foundry"
        class="chrome:sidebar_item chrome:sidebar_item_collapsible chrome:sidebar_item_collapsed"
        onclick="toggleAccordian('sidebar_item:ansible foundry')"
      >
        <span class="chrome:sidebar_item_text">Ansible Foundry</span>
        <div class="chrome:collapsible_sub_nav_item_icon">
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="12"
    height="12"
    viewBox="0 0 12 12"
    focusable="false"
    role="presentation"
  >
    <path
      fill="currentColor"
      d="M1.646 3.646a.5.5 0 01.638-.057l.07.057L6 7.293l3.646-3.647a.5.5 0 01.638-.057l.07.057a.5.5 0 01.057.638l-.057.07-4 4a.5.5 0 01-.638.057l-.07-.057-4-4a.5.5 0 010-.708z"
    ></path>
  </svg>
</div>

      </button>
      <div id="sidebar_item:ansible foundry:accordian"
        class="chrome:sidebar_item_accordian chrome:sidebar_item_accordian_collapsed">
        
          
          
          
          <a href="/docs/content/ansible_intro/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            Introduction
          </a>
          
        
          
          
          
          <a href="/docs/content/ansible_developers/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            Goal-oriented Guides
          </a>
          
        
          
          
          
          <a href="/docs/content/ansible_info/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            References
          </a>
          
        
          
          
          
          <a href="/docs/content/ansible_troubleshoot/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            Operations
          </a>
          
        
      </div>
    
  
    
      
      
      
      <button
        id="sidebar_item:cdp pvc data services"
        class="chrome:sidebar_item chrome:sidebar_item_collapsible chrome:sidebar_item_expanded"
        onclick="toggleAccordian('sidebar_item:cdp pvc data services')"
      >
        <span class="chrome:sidebar_item_text">CDP PvC Data Services</span>
        <div class="chrome:collapsible_sub_nav_item_icon">
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="12"
    height="12"
    viewBox="0 0 12 12"
    focusable="false"
    role="presentation"
  >
    <path
      fill="currentColor"
      d="M1.646 3.646a.5.5 0 01.638-.057l.07.057L6 7.293l3.646-3.647a.5.5 0 01.638-.057l.07.057a.5.5 0 01.057.638l-.057.07-4 4a.5.5 0 01-.638.057l-.07-.057-4-4a.5.5 0 010-.708z"
    ></path>
  </svg>
</div>

      </button>
      <div id="sidebar_item:cdp pvc data services:accordian"
        class="chrome:sidebar_item_accordian chrome:sidebar_item_accordian_expanded">
        
          
          
          
          <a href="/docs/content/ecs_env/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            ECS: Client
          </a>
          
        
          
          
          
          <a href="/docs/content/ecs_lvm/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            ECS: LVM
          </a>
          
        
          
          
          
          <a href="/docs/content/ecs_gpu/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            ECS: GPU
          </a>
          
        
          
          
          
          <a href="/docs/content/ecs_addnode/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            ECS: Add ECS Node
          </a>
          
        
          
          
          
          <a href="/docs/content/ecs_removenode/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            ECS: Remove Node
          </a>
          
        
          
          
          
          <a href="/docs/content/ocp_gpu/" class="chrome:sidebar_item text-sm chrome:active_sidebar_item chrome:sidebar_item_child">
            OCP: GPU
          </a>
          
        
          
          
          
          <a href="/docs/content/ocp_cdwdisk/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            OCP: CDW Disk
          </a>
          
        
          
          
          
          <a href="/docs/content/cml_autotls/" class="chrome:sidebar_item text-sm  chrome:sidebar_item_child">
            CML: CSR with AutoTLS
          </a>
          
        
      </div>
    
  
    
      
      
      
      <a href="/docs/development/" class="chrome:sidebar_item ">
        <span class="chrome:sidebar_item_text">Coming Soon</span>
      </a>
      
    
  
</div>
 
        </div>
        <footer class="chrome:footer"><div class="chrome:footer_item">
    <span class="text-lg"
      >Updated: 2022-11-21 15:51</span
    >
  </div>
</footer>

      </div>
    </div>
    
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        let theme = "forest";
        mermaid.initialize({ startOnLoad: true, theme });
        window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid'));
    </script>
    
  </body>
</html>
